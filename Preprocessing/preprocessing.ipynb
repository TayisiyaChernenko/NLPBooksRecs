{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'book_id', 'review_id', 'rating', 'review_text',\n",
      "       'date_added', 'date_updated', 'read_at', 'started_at', 'n_votes',\n",
      "       'n_comments'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define your bucket name and file path\n",
    "bucket_name = 'abbynlpproject'\n",
    "file_key = 'goodreads_reviews_fantasy_paranormal.json.gz'\n",
    "\n",
    "# Download the file from S3 to local memory\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "\n",
    "# Decompress the .gz file\n",
    "with gzip.GzipFile(fileobj=BytesIO(obj['Body'].read()), mode='rb') as f:\n",
    "    # Read the file line by line (assuming each line is a separate JSON object)\n",
    "    data = []\n",
    "    for line in f:\n",
    "        try:\n",
    "            # Decode each line, parse it as JSON and append to the data list\n",
    "            data.append(json.loads(line.decode('utf-8')))\n",
    "        except json.JSONDecodeError:\n",
    "            continue  # Skip any malformed lines or invalid JSON objects\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check the columns of the book metadata dataframe\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    book_id                                        review_text  rating\n",
      "0  18245960  This is a special book. It started slow for ab...       5\n",
      "1   5577844  A beautiful story. Neil Gaiman is truly a uniq...       5\n",
      "2  17315048  Mark Watney is a steely-eyed missile man. A ma...       5\n",
      "3  13453029  A fun fast paced book that sucks you in right ...       4\n",
      "4  13239822  This book has a great premise, and is full of ...       3\n"
     ]
    }
   ],
   "source": [
    "# Keep only the 'book_id' and 'review_text' columns\n",
    "df_cleaned = df[['book_id', 'review_text', 'rating']]\n",
    "\n",
    "# Display the cleaned dataframe\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['isbn', 'text_reviews_count', 'series', 'country_code', 'language_code',\n",
      "       'popular_shelves', 'asin', 'is_ebook', 'average_rating', 'kindle_asin',\n",
      "       'similar_books', 'description', 'format', 'link', 'authors',\n",
      "       'publisher', 'num_pages', 'publication_day', 'isbn13',\n",
      "       'publication_month', 'edition_information', 'publication_year', 'url',\n",
      "       'image_url', 'book_id', 'ratings_count', 'work_id', 'title',\n",
      "       'title_without_series'],\n",
      "      dtype='object')\n",
      "                            user_id   book_id  \\\n",
      "0  8842281e1d1347389f2ab93d60773d4d  18245960   \n",
      "1  8842281e1d1347389f2ab93d60773d4d   5577844   \n",
      "2  8842281e1d1347389f2ab93d60773d4d  17315048   \n",
      "3  8842281e1d1347389f2ab93d60773d4d  13453029   \n",
      "4  8842281e1d1347389f2ab93d60773d4d  13239822   \n",
      "\n",
      "                          review_id  rating  \\\n",
      "0  dfdbb7b0eb5a7e4c26d59a937e2e5feb       5   \n",
      "1  52c8ac49496c153e4a97161e36b2db55       5   \n",
      "2  885c772fb033b041f42d57cef5be0a43       5   \n",
      "3  46a6e1a14e8afc82d221fec0a2bd3dd0       4   \n",
      "4  a582bfa8efd69d453a5a21a678046b36       3   \n",
      "\n",
      "                                         review_text  \\\n",
      "0  This is a special book. It started slow for ab...   \n",
      "1  A beautiful story. Neil Gaiman is truly a uniq...   \n",
      "2  Mark Watney is a steely-eyed missile man. A ma...   \n",
      "3  A fun fast paced book that sucks you in right ...   \n",
      "4  This book has a great premise, and is full of ...   \n",
      "\n",
      "                       date_added                    date_updated  \\\n",
      "0  Sun Jul 30 07:44:10 -0700 2017  Wed Aug 30 00:00:26 -0700 2017   \n",
      "1  Wed Sep 24 09:29:29 -0700 2014  Wed Oct 01 00:31:56 -0700 2014   \n",
      "2  Sat Apr 05 09:30:53 -0700 2014  Wed Mar 22 11:33:10 -0700 2017   \n",
      "3  Tue Dec 04 11:12:22 -0800 2012  Sat Jul 26 11:43:28 -0700 2014   \n",
      "4  Mon Jul 02 16:04:16 -0700 2012  Wed Mar 22 11:32:20 -0700 2017   \n",
      "\n",
      "                          read_at                      started_at  n_votes  \\\n",
      "0  Sat Aug 26 12:05:52 -0700 2017  Tue Aug 15 13:23:18 -0700 2017       28   \n",
      "1  Tue Sep 30 00:00:00 -0700 2014  Sun Sep 21 00:00:00 -0700 2014        5   \n",
      "2  Mon Aug 25 00:00:00 -0700 2014  Sat Aug 16 00:00:00 -0700 2014       25   \n",
      "3  Tue Jul 08 00:00:00 -0700 2014  Wed Jul 02 00:00:00 -0700 2014        5   \n",
      "4  Wed Aug 15 00:00:00 -0700 2012  Sun Aug 12 00:00:00 -0700 2012        7   \n",
      "\n",
      "   n_comments                                              title  \n",
      "0           1  The Three-Body Problem (Remembrance of Earth’s...  \n",
      "1           1                                           Stardust  \n",
      "2           5                                        The Martian  \n",
      "3           1                            Wool Omnibus (Silo, #1)  \n",
      "4           0                                    Alif the Unseen  \n"
     ]
    }
   ],
   "source": [
    "# Define your file key for the book metadata\n",
    "book_metadata_key = 'goodreads_books_fantasy_paranormal.json.gz'\n",
    "\n",
    "# Download the book metadata file from S3\n",
    "book_metadata_obj = s3.get_object(Bucket=bucket_name, Key=book_metadata_key)\n",
    "\n",
    "# Decompress and load the book metadata (similar to the reviews data)\n",
    "with gzip.GzipFile(fileobj=BytesIO(book_metadata_obj['Body'].read()), mode='rb') as f:\n",
    "    book_metadata = []\n",
    "    for line in f:\n",
    "        try:\n",
    "            # Decode and parse the JSON data\n",
    "            book_metadata.append(json.loads(line.decode('utf-8')))\n",
    "        except json.JSONDecodeError:\n",
    "            continue  # Skip any malformed lines\n",
    "\n",
    "# Convert the book metadata list to a DataFrame\n",
    "df_books = pd.DataFrame(book_metadata)\n",
    "\n",
    "# Check the columns of the book metadata dataframe\n",
    "print(df_books.columns)\n",
    "\n",
    "# Assuming the column name is 'title' (or whatever is appropriate), use that to merge\n",
    "df_with_book_names = pd.merge(df, df_books[['book_id', 'title']], on='book_id', how='left')\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(df_with_book_names.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abbyeast/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/abbyeast/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_text  \\\n",
      "0  This is a special book. It started slow for ab...   \n",
      "1  A beautiful story. Neil Gaiman is truly a uniq...   \n",
      "2  Mark Watney is a steely-eyed missile man. A ma...   \n",
      "3  A fun fast paced book that sucks you in right ...   \n",
      "4  This book has a great premise, and is full of ...   \n",
      "\n",
      "                                 cleaned_review_text  \n",
      "0  special book started slow first third middle t...  \n",
      "1  beautiful story neil gaiman truly unique story...  \n",
      "2  mark watney steelyeyed missile man man man bad...  \n",
      "3  fun fast paced book suck right away doesnt let...  \n",
      "4  book great premise full beautifully written pr...  \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download the stopwords and lemmatizer if you haven't already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text (split it into words)\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stopwords and lemmatize the remaining words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join the words back into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the preprocessing function to the review_text column\n",
    "df_with_book_names['cleaned_review_text'] = df_with_book_names['review_text'].apply(preprocess_text)\n",
    "\n",
    "# Check the first few rows after preprocessing\n",
    "print(df_with_book_names[['review_text', 'cleaned_review_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>book_id</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Three-Body Problem (Remembrance of Earth’s...</td>\n",
       "      <td>18245960</td>\n",
       "      <td>special book started slow first third middle t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stardust</td>\n",
       "      <td>5577844</td>\n",
       "      <td>beautiful story neil gaiman truly unique story...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Martian</td>\n",
       "      <td>17315048</td>\n",
       "      <td>mark watney steelyeyed missile man man man bad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wool Omnibus (Silo, #1)</td>\n",
       "      <td>13453029</td>\n",
       "      <td>fun fast paced book suck right away doesnt let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alif the Unseen</td>\n",
       "      <td>13239822</td>\n",
       "      <td>book great premise full beautifully written pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   book_id  \\\n",
       "0  The Three-Body Problem (Remembrance of Earth’s...  18245960   \n",
       "1                                           Stardust   5577844   \n",
       "2                                        The Martian  17315048   \n",
       "3                            Wool Omnibus (Silo, #1)  13453029   \n",
       "4                                    Alif the Unseen  13239822   \n",
       "\n",
       "                                 cleaned_review_text  \n",
       "0  special book started slow first third middle t...  \n",
       "1  beautiful story neil gaiman truly unique story...  \n",
       "2  mark watney steelyeyed missile man man man bad...  \n",
       "3  fun fast paced book suck right away doesnt let...  \n",
       "4  book great premise full beautifully written pr...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_df = df_with_book_names[['title', 'book_id', 'cleaned_review_text']]\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to S3: s3://abbynlpproject/cleaned_goodreads_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define S3 bucket and filename\n",
    "bucket_name = 'abbynlpproject'\n",
    "file_key = 'cleaned_goodreads_reviews.csv'\n",
    "\n",
    "# Convert DataFrame to CSV in memory\n",
    "csv_buffer = StringIO()\n",
    "cleaned_df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Upload to S3\n",
    "s3.put_object(Bucket=bucket_name, Key=file_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"File saved to S3: s3://{bucket_name}/{file_key}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
